<!--
=========================================================
* Material Kit 2 - v3.0.2
=========================================================

* Product Page: https://www.creative-tim.com/product/material-kit
* Copyright 2022 Creative Tim (https://www.creative-tim.com)
* Licensed under MIT (https://www.creative-tim.com/license)
* Coded by Creative Tim

=========================================================

* The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="apple-touch-icon" sizes="76x76" href="../assets/img/apple-icon.png">
  <link rel="icon" type="image/png" href="../assets/img/favicon.png">
  <title>
    UbiNet@CSE,IITKGP
  </title>
  <!--     Fonts and icons     -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900|Roboto+Slab:400,700" />
  <!-- Nucleo Icons -->
  <link href="../assets/css/nucleo-icons.css" rel="stylesheet" />
  <link href="../assets/css/nucleo-svg.css" rel="stylesheet" />
  <!-- Font Awesome Icons -->
  <script src="https://kit.fontawesome.com/42d5adcbca.js" crossorigin="anonymous"></script>
  <!-- Material Icons -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons+Round" rel="stylesheet">
  <!-- CSS Files -->
  <link id="pagestyle" href="../assets/css/material-kit.css?v=3.0.2" rel="stylesheet" />
</head>

<body class="inputs-sections">
  <!-- Navbar Transparent -->
  <nav class="navbar navbar-expand-lg position-absolute top-0 z-index-3 w-100 shadow-none my-3  navbar-transparent ">
    <div class="container">
      <a class="navbar-brand  text-white " href="../index.html" rel="tooltip" title="Designed and Coded by Creative Tim" data-placement="bottom" target="_blank">
        <b>UbiNet@CSE,IITKGP</b>
      </a>
      <button class="navbar-toggler shadow-none ms-2" type="button" data-bs-toggle="collapse" data-bs-target="#navigation" aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon mt-2">
          <span class="navbar-toggler-bar bar1"></span>
          <span class="navbar-toggler-bar bar2"></span>
          <span class="navbar-toggler-bar bar3"></span>
        </span>
      </button>
      <div class="collapse navbar-collapse w-100 pt-3 pb-2 py-lg-0 ms-lg-12 ps-lg-5" id="navigation">
        <ul class="navbar-nav navbar-nav-hover ms-auto">
          <li class="nav-item dropdown dropdown-hover mx-2 ms-lg-6">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" href="../index.html">
              <i class="material-icons opacity-6 me-2 text-md">dashboard</i>
              Home
              <!--<img src="assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">
              <img src="assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">-->
            </a>
          </li>
          <li class="nav-item dropdown dropdown-hover mx-2">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" href="../publications/index.html">
              <i class="material-icons opacity-6 me-2 text-md">view_day</i>
              Publications
              <!--<img src="assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">-->
              <!--<img src="assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">-->
            </a>
          </li>
          <li class="nav-item dropdown dropdown-hover mx-2">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" id="dropdownMenuDocs" data-bs-toggle="dropdown" aria-expanded="false">
              <i class="material-icons opacity-6 me-2 text-md">article</i>
              Research Areas
              <img src="../assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">
              <img src="../assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">
            </a>
            <ul class="dropdown-menu dropdown-menu-animation dropdown-menu-end dropdown-md dropdown-md-responsive mt-0 mt-lg-3 p-3 border-radius-lg" aria-labelledby="dropdownMenuDocs">
              <div class="d-none d-lg-block">
                <ul class="list-group">
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="#">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Sensing</h6>
                      <span class="text-sm">Smartphones, Wearables, Sensors</span>
                    </a>
                  </li>
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="./research_hci.html">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Computer Human Interaction</h6>
                      <span class="text-sm">Assistive Systems, Human Machine Interfacing</span>
                    </a>
                  </li>
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="./research_ds.html">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Distributed Systems</h6>
                      <span class="text-sm">Cloud, Edge, Blockchains</span>
                    </a>
                  </li>
                  <li class="nav-item list-group-item border-0 p-0">
                    <a class="dropdown-item py-2 ps-3 border-radius-md" href="./research_network.html">
                      <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Networking</h6>
                      <span class="text-sm">Protocols, Quality, Applications</span>
                    </a>
                  </li>
                </ul>
              </div>
              <div class="row d-lg-none">
                <div class="col-md-12 g-0">
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="./research_sensing.html">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Sensing</h6>
                    <span class="text-sm">Smartphones, Wearables, Sensors</span>
                  </a>
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="./research_hci.html">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Computer Human Interaction</h6>
                    <span class="text-sm">Assistive Systems, Human Machine Interfacing</span>
                  </a>
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="./research_ds.html">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Distributed Systems</h6>
                    <span class="text-sm">Cloud, Edge, Blockchains</span>
                  </a>
                  <a class="dropdown-item py-2 ps-3 border-radius-md" href="./research_network.html">
                    <h6 class="dropdown-header text-dark font-weight-bolder d-flex justify-content-cente align-items-center p-0">Networking</h6>
                    <span class="text-sm">Protocols, Quality, Applications</span>
                  </a>
                </div>
              </div>
            </ul>
          </li>
          <li class="nav-item dropdown dropdown-hover mx-2">
            <a class="nav-link ps-2 d-flex justify-content-between cursor-pointer align-items-center" href="./projects.html">
              <i class="fa fa-handshake me-1"></i>
              Sponsored Projects
              <!--<img src="assets/img/down-arrow-white.svg" alt="down-arrow" class="arrow ms-2 d-lg-block d-none">
              <img src="assets/img/down-arrow-dark.svg" alt="down-arrow" class="arrow ms-2 d-lg-none d-block">-->
            </a>
          </li>
        </ul>
      </div>
    </div>
  </nav>
  <!-- End Navbar -->
   <!-- -------- START HEADER 7 w/ text and video ------- -->
  <header class="bg-gradient-dark">
    <div class="page-header min-vh-50" style="background-image: url('../assets/img/bgiit.jpg');">
      <span class="mask bg-gradient-dark opacity-6"></span>
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-8 text-center mx-auto my-auto">
            <h1 class="text-white">Research @ Ubiquitous Networked Systems Lab</h1>
            <!-- <p class="lead mb-4 text-white opacity-8">We’re constantly trying to push the boundaries of sensing and systems research. Come along if you share the same ambition.</p>
            <button class="btn bg-white text-dark">Research Highlights</button>
            <h6 class="text-white mb-2 mt-5">Follow us on</h6>
            <div class="d-flex justify-content-center">
              <a href="#"><i class="fab fa-facebook text-lg text-white me-4"></i></a>
              <a href="#"><i class="fab fa-instagram text-lg text-white me-4"></i></a>
              <a href="#"><i class="fab fa-twitter text-lg text-white me-4"></i></a>
              <a href="#"><i class="fab fa-google-plus text-lg text-white"></i></a>
            </div> -->
          </div>
        </div>
      </div>
    </div>
  </header>
  <!-- -------- END HEADER 7 w/ text and video ------- -->
  <div class="container mt-8">
    <div class="row">
      <div class="col-lg-12 mx-auto">
        <!--<h2>Research Focus @ UbiNet</h2>-->
        <hr>
          
        <!-- Sensing -->
          
        <div class="position-relative border-radius-xl overflow-hidden shadow-lg mb-7">
          <div class="container border-bottom">
                <h2>Sensing</h2>
          </div>
          <div class="tab-content tab-space p-3">
            <p> Pervasive sensing is the primary focus of our research group. We sense everything, humans and the environment, and with different modalities, like the locomotive, acoustic, RF, medical, etc., under different infrastructures, like active and passive sensing, wearables, fixed-infrastructure, sensing, etc. The objective is to develop ubiquitous applications that can be leveraged through low-cost sensing infrastructure. We use different technologies, like signal processing, machine learning, deep learning, etc., from the algorithmic perspective to meet our goals. Some of our recent exciting projects are as follows.</p>
            
            <h5>Passive Sensing: Using RF to Sense Human, Environment and Conexts</h5>
            <p>Imagine living in an intuitive interactive space without a need to understand the grammar of interaction with that space. One doesn't need to interact in a specific way or use voice commands or always wear something. This intelligent space can be shared with others without degrading the user experience of interaction. Interestingly, this vision of seamless smart spaces is not novel and quite dated; however, we are yet to occupy this kind of space regularly. For this vision to become an everyday reality, we are working on developing passive sensing systems, primarily using RF (such as mmWave), to monitor not only the humans, but also the environment and the context of interactions. To realize this with an application, we developed a passive driving behavior monitoring device using mmWave sensing. We are also working on developing platforms for continuous monitoring of multi-user activities at different scale (ADLs, IADLs, excericses, etc.) using such passive sensing architecture.<br><br>
              <iframe width="380" height="212" src="https://www.youtube.com/embed/Pf5jx1EHGWE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              <iframe width="380" height="212" src="https://www.youtube.com/embed/tLCQYIf7t1c" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              </p>
            <h5>Smart Transportation: Sensing the Road, the Vehicle, and the Driver</h5>
              <p>Road travel in developing countries, particularly in the Indian subcontinent, is very sporadic because of multiple socio-economic factors. The roads are bumpy in many places; infrastructure is not very good, the streets are congested due to heavy traffic, and so on. We develop pervasive sensing modalities to sense the road, the transport infrastructure, and the driver. One critical issue is understanding various points of interest (PoIs) on the road, which affect travel. We use smartphone-based crowdsensing, leveraging the embedded sensors on today's smartphones like IMU, GPS, etc., to capture various PoIs and tag them over the map. another crucial issues is monitoring a driver's driving behavior and how the driver interacts with various landmarks on the road, like speed breakers, potholes, turns, etc. We also aim to understand the driving behavior and its impact and interactions on different maneuvers taken by the driver. Collectively, we target the lifestyle of citizens on the road to develop assistive technologies to support them during their daily commute.<br><br>
                <iframe width="380" height="212" src="https://www.youtube.com/embed/r9KtejjXpPw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
                <iframe width="380" height="212" src="https://www.youtube.com/embed/vgzzV-UNFfE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>   
                <iframe width="380" height="212" src="https://www.youtube.com/embed/a12gc6Bdq2M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p>
              <h5>Human Sensing: Activity Recognition and Annotation</h5>
              <p>Human activity recognition (HAR) has been one of the essential building blocks behind various pervasive applications. We are working on developing lightweight and cost-effective approaches for HAR, starting from macro-activities, like walking, running, writing on a board, meeting group detection, etc., to micro and fine-grained activities like cooking in a smart-home scenario. We use various modalities, like IMU, acoustic, RF, etc., for inferring the activities. Another area of our prime focus is activity annotation. The typical HAR models work in a supervised environment; therefore, they need a massive amount of labeled data to train the models. The question is, how do we label or annotate this data? We work to develop a robust and automated approach to use auxiliary sensing modalities, like acoustic, to label the IMU data for activity recognition. This is a challenging problem as the method does not have any prior knowledge; therefore, it needs to work in an unsupervised way. We also work on understanding the granularity and informativeness of these labels and how the generated labels can contribute to the development of large-scale activity recognition models.<br><br> 
               <iframe width="380" height="212" src="https://www.youtube.com/embed/fPeB20pJPEs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
               <iframe width="380" height="212" src="https://www.youtube.com/embed/-OdEqAd6E8s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
               <iframe width="380" height="212" src="https://www.youtube.com/embed/_zVN5e9N6o8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
               <iframe width="380" height="212" src="https://www.youtube.com/embed/KAuUhk3PtWk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
              </p>
              <h5>Environment Sensing: Making the World a Smart Place to Live</h5>
              <p> Of late, we started working on sensing the environment. <a href="https://www.iqair.com/in-en/world-most-polluted-cities" target="_blank">Six out of top 10 polluted cities in the world are from India.</a> We aim to develop a low-cost, portable pollution monitoring device that can help individuals sense the environment for the presence of different pollutants in outdoor and indoor environments. We also work on designing an efficient mechanism for deciding the placement of pollution monitoring devices in an indoor setup, understand the impact of pollutants on the cognitive and behavioral aspects of humans, and understand the impact of several indoor activities on the pollution level of the room.    
              </p>
              <h5>Affective Sensing: Understand Human Behavior from Passive Sensing</h5>
              <p>There has been a recent development in designing applications based on behavioral HCI, for example, emotion-aware music player, facial expression-based device control, etc. Recently we started working towards exploring passive sensing technologies, such as mmWave sensing, acoustic sensing, etc., towards understanding the user's facial expressions, emotions, and behavioral aspects. Typical, different facial expressions result from a set of Action Units (AU) (facial muscle movements). Such facial muscle movements are the building blocks of expressions and can be categorized under ocular (around eye region), nasal (around nose region), and oral (around mouth area) groups. For example, a particular expression, say "Happiness," is a combination of facial muscle movements, majorly around the oral region and subtly around the ocular and nasal areas. We aim to use various passive sensing technologies, such as acoustic sensing, mmWave radar-based sensing, smartphone-embedded LiDAR, etc., to sense the user's facial expression.<br><br>
              <iframe width="380" height="212" src="https://www.youtube.com/embed/p5IqMn4Q7FM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              </p>
          </div>
        </div>

      </div>
    </div>
  </div>
  <!-- -------- START FOOTER 3 w/ COMPANY DESCRIPTION WITH LINKS & SOCIAL ICONS & COPYRIGHT ------- -->
  <footer class="footer py-5">
    <div class="container">
      <div class="row">
        <div class="col-8 mx-auto text-center mt-1">
          <p class="mb-0 text-secondary">
            Copyright © <script>
              document.write(new Date().getFullYear())
            </script> UbiNet@CSE,IITKGP
          </p>
        </div>
      </div>
    </div>
  </footer>
  <!-- -------- END FOOTER 3 w/ COMPANY DESCRIPTION WITH LINKS & SOCIAL ICONS & COPYRIGHT ------- -->
  <!--   Core JS Files   -->
  <script src="../assets/js/core/popper.min.js" type="text/javascript"></script>
  <script src="../assets/js/core/bootstrap.min.js" type="text/javascript"></script>
  <script src="../assets/js/plugins/perfect-scrollbar.min.js"></script>
  <script src="../assets/js/plugins/prism.min.js"></script>
  <script src="../assets/js/plugins/highlight.min.js"></script>
  <!--  Plugin for Parallax, full documentation here: https://github.com/wagerfield/parallax  -->
  <script src="../assets/js/plugins/parallax.min.js"></script>
  <!-- Control Center for Material UI Kit: parallax effects, scripts for the example pages etc -->
  <!--  Google Maps Plugin    -->
  <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyDTTfWur0PDbZWPr7Pmq8K3jiDp0_xUziI"></script>
  <script src="../assets/js/material-kit.min.js?v=3.0.2" type="text/javascript"></script>
</body>

</html>
